\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{elsarticle-num}
\emailauthor{michael.hornacek@tuwien.ac.at}{Michael Horn\'{a}\v {c}ek}
\Newlabel{mycorrespondingauthor}{1}
\citation{van2010survey,zhou2008trends}
\citation{schlund2018moglichkeiten,uva2018evaluating,masood2019augmented,gattullo2019towards,aschenbrenner2019comparing,mayrhofer2019one,rupprecht2020information,Rupprecht2021}
\citation{hololens}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}\protected@file@percent }
\newlabel{sec:intro}{{1}{2}{Introduction}{section.1}{}}
\citation{bimber2019spatial}
\citation{aschenbrenner2019comparing}
\citation{mayrhofer2019one}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Na\"ive projection to a given target location in the scene plane (e.g., the floor, a wall, or table) if not facing the scene plane directly. (a) Original image, which we wish to project to the scene plane. (b) Projecting the original image to the scene plane from the viewpoint of the projector (shown as a frustum in the bottom left, in black with up vector red) directed to the target location introduces projective distortions if the projector does not face the scene plane directly (as is the case here), with orientation and scale of the augmentation varying in the scene plane as a function of target location.\relax }}{4}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:proj}{{1}{4}{Na\"ive projection to a given target location in the scene plane (e.g., the floor, a wall, or table) if not facing the scene plane directly. (a) Original image, which we wish to project to the scene plane. (b) Projecting the original image to the scene plane from the viewpoint of the projector (shown as a frustum in the bottom left, in black with up vector red) directed to the target location introduces projective distortions if the projector does not face the scene plane directly (as is the case here), with orientation and scale of the augmentation varying in the scene plane as a function of target location.\relax }{figure.caption.1}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {\centering Original image (to be projected).}}}{4}{subfigure.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {\centering Projection from side to scene plane (viewed directly downwards to scene plane).}}}{4}{subfigure.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Projection to a given target location in the scene plane, correcting for projective distortions in terms of a \textit  {virtual} projector placed and utilized according to our approach. (a) Original image (cf.\ Figure\nobreakspace  {}\ref  {fig:proj}(a)) warped using our approach. (b) Projecting the warped image to the scene plane from the viewpoint of the projector (bottom left, frustum in black with up vector red; same as in Figure\nobreakspace  {}\ref  {fig:proj}(b)) directed to the target location has the effect of projecting the \textit  {original} image from the viewpoint of a virtual projector (center, frustum in gray with up vector red). This renders the projection free of projective distortions, oriented in accordance with the axes of the `downwards-facing' camera, and at the desired metric scale. Note that black pixels will in effect be ignored by the projector.\relax }}{5}{figure.caption.2}\protected@file@percent }
\newlabel{fig:warp}{{2}{5}{Projection to a given target location in the scene plane, correcting for projective distortions in terms of a \textit {virtual} projector placed and utilized according to our approach. (a) Original image (cf.\ Figure~\ref {fig:proj}(a)) warped using our approach. (b) Projecting the warped image to the scene plane from the viewpoint of the projector (bottom left, frustum in black with up vector red; same as in Figure~\ref {fig:proj}(b)) directed to the target location has the effect of projecting the \textit {original} image from the viewpoint of a virtual projector (center, frustum in gray with up vector red). This renders the projection free of projective distortions, oriented in accordance with the axes of the `downwards-facing' camera, and at the desired metric scale. Note that black pixels will in effect be ignored by the projector.\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {\centering Our warped image (to be projected).}}}{5}{subfigure.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {\centering Projection from side to scene plane (viewed directly downwards to scene plane).}}}{5}{subfigure.2.2}\protected@file@percent }
\citation{pinhanez2001everywhere}
\citation{kjeldsen2002interacting,pinhanez2003applications}
\citation{Hartley2004}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Related Work}{6}{subsection.1.1}\protected@file@percent }
\citation{Hartley2004}
\citation{sukthankar2001smarter}
\citation{raskar2001self}
\citation{Hartley2004}
\citation{bimber2019spatial}
\citation{Hartley2004}
\citation{Hartley2004}
\citation{duane1971close,weng1992camera}
\@writefile{toc}{\contentsline {section}{\numberline {2}Approach}{8}{section.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Obtaining the 3D positions of the 2D-3D correspondences for use in projector calibration. (a) For each target location, a projector calibration image is acquired from the viewpoint of the `downwards-facing' camera, containing a projected asymmetric circle pattern at the target location and a chessboard pattern placed on the floor nearby. Circle pattern center points and chessboard corners detected automatically (overlain for illustration). (b) Given a projector calibration image, the scene plane is recovered in the coordinate frame of the `downwards-facing' camera (frustum in black with up vector red) via spatial resection with respect to 2D-3D correspondences obtained using the chessboard pattern (blue), with 3D positions known \textit  {a priori}. With the scene plane available, the 3D positions of the projected asymmetric circles pattern to be used in calibrating the projector (red, in scene plane) are obtained by intersection with the scene plane of the back-projections (gray rays) of the detected 2D center points of the circle pattern (red, in image plane of camera).\relax }}{9}{figure.caption.3}\protected@file@percent }
\newlabel{fig:2d}{{3}{9}{Obtaining the 3D positions of the 2D-3D correspondences for use in projector calibration. (a) For each target location, a projector calibration image is acquired from the viewpoint of the `downwards-facing' camera, containing a projected asymmetric circle pattern at the target location and a chessboard pattern placed on the floor nearby. Circle pattern center points and chessboard corners detected automatically (overlain for illustration). (b) Given a projector calibration image, the scene plane is recovered in the coordinate frame of the `downwards-facing' camera (frustum in black with up vector red) via spatial resection with respect to 2D-3D correspondences obtained using the chessboard pattern (blue), with 3D positions known \textit {a priori}. With the scene plane available, the 3D positions of the projected asymmetric circles pattern to be used in calibrating the projector (red, in scene plane) are obtained by intersection with the scene plane of the back-projections (gray rays) of the detected 2D center points of the circle pattern (red, in image plane of camera).\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {\centering Projector calibration image (2D position detections of chessboard pattern and asymmetric circle pattern overlain).}}}{9}{subfigure.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {\centering Recovery of corresponding 3D positions of asymmetric circle pattern for use in projector calibration (red, in scene plane).}}}{9}{subfigure.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Recovering Geometry}{9}{subsection.2.1}\protected@file@percent }
\newlabel{sec:approach:geometry}{{2.1}{9}{Recovering Geometry}{subsection.2.1}{}}
\citation{Hartley2004}
\citation{triggs1999bundle}
\citation{Hartley2004,zhang2000flexible}
\citation{duane1971close,weng1992camera}
\newlabel{re}{{2}{10}{Recovering Geometry}{equation.2.2}{}}
\citation{moreno2012simple,zhang2009projector,zhang2006novel}
\citation{bradski2000opencv}
\@writefile{toc}{\contentsline {paragraph}{2D-3D correspondences for camera calibration}{11}{section*.4}\protected@file@percent }
\citation{Hartley2004}
\citation{collins2014infinitesimal}
\citation{bradski2000opencv}
\@writefile{toc}{\contentsline {paragraph}{2D-3D correspondences for projector calibration}{12}{section*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Correcting for Projective Distortion}{13}{subsection.2.2}\protected@file@percent }
\newlabel{sec:approach:homography}{{2.2}{13}{Correcting for Projective Distortion}{subsection.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Obtaining the virtual camera. Our physical `downwards-facing' camera---placed to face downwards towards the scene plane, and in terms of whose rotation relative to the normal vector of the scene plane we wish to orient our augmentations---is almost certain to not face downwards towards the scene plane directly. Accordingly, we rotate the recovered `downwards-facing' camera (frustum in black) about its center of projection such that its optical axis be made parallel with the scene plane's normal, with respect to the minimum arc-length rotation relating the two. It is the $X$- and $Y$-axes of the virtual camera that we then use to set the $X$- and $Y$-axes of the virtual projector.\relax }}{14}{figure.caption.6}\protected@file@percent }
\newlabel{fig:virtualcam}{{4}{14}{Obtaining the virtual camera. Our physical `downwards-facing' camera---placed to face downwards towards the scene plane, and in terms of whose rotation relative to the normal vector of the scene plane we wish to orient our augmentations---is almost certain to not face downwards towards the scene plane directly. Accordingly, we rotate the recovered `downwards-facing' camera (frustum in black) about its center of projection such that its optical axis be made parallel with the scene plane's normal, with respect to the minimum arc-length rotation relating the two. It is the $X$- and $Y$-axes of the virtual camera that we then use to set the $X$- and $Y$-axes of the virtual projector.\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {\centering Oblique view (annotated).}}}{14}{subfigure.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {\centering View directly downwards to scene\nobreakspace {}plane.}}}{14}{subfigure.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Virtual camera and projector}{15}{section*.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Obtaining the virtual projector, with $X$- and $Y$-axes aligned with those of the virtual camera (cf.\ Figure\nobreakspace  {}\ref  {fig:virtualcam}). For a given target location, the virtual projector is obtained by (i) rotating the recovered projector (bottom left, frustum in black) about the point of intersection of its optical axis with the scene plane such that the optical axis be made parallel with the scene plane's normal vector, (ii) rotating the $X$- and $Y$-axes to align them with those of the virtual camera facing \textit  {directly} downwards to the scene plane (cf.\ Figure \ref  {fig:virtualcam}), and (iii) translating along the normal direction to achieve the desired metric projected image dimensions. Projection from the viewpoint of the virtual projector thus produces an augmentation absent of projective distortions, aligns the augmentation {in accordance with} the horizontal and vertical image axes of the `downwards-facing' camera, and ensures the augmentation appears in the scene plane with the desired metric dimensions.\relax }}{16}{figure.caption.8}\protected@file@percent }
\newlabel{fig:virtualproj}{{5}{16}{Obtaining the virtual projector, with $X$- and $Y$-axes aligned with those of the virtual camera (cf.\ Figure~\ref {fig:virtualcam}). For a given target location, the virtual projector is obtained by (i) rotating the recovered projector (bottom left, frustum in black) about the point of intersection of its optical axis with the scene plane such that the optical axis be made parallel with the scene plane's normal vector, (ii) rotating the $X$- and $Y$-axes to align them with those of the virtual camera facing \textit {directly} downwards to the scene plane (cf.\ Figure \ref {fig:virtualcam}), and (iii) translating along the normal direction to achieve the desired metric projected image dimensions. Projection from the viewpoint of the virtual projector thus produces an augmentation absent of projective distortions, aligns the augmentation \texit {in accordance with} the horizontal and vertical image axes of the `downwards-facing' camera, and ensures the augmentation appears in the scene plane with the desired metric dimensions.\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {\centering Oblique view (annotated).}}}{16}{subfigure.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {\centering View directly downwards to scene\nobreakspace {}plane.}}}{16}{subfigure.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Projection of the warped image from Figure \ref  {fig:warp}(a) to corresponding target location at the upper-right corner of the floorspace, acquired by the `downwards-facing' camera. Note that besides correcting for projective distortions, the warp places the axes of the augmentation in accordance with the axes of the `downwards-facing' camera, and that the dimensions of the augmentation are in line with the desired target dimensions (50\nobreakspace  {}cm\nobreakspace  {}$\times $\nobreakspace  {}31.25\nobreakspace  {}cm). To provide context, the corners of the full projected image extent are projected to the floor in light green (emphasized with overlain dashed circles).\relax }}{17}{figure.caption.9}\protected@file@percent }
\newlabel{fig:final_proj}{{6}{17}{Projection of the warped image from Figure \ref {fig:warp}(a) to corresponding target location at the upper-right corner of the floorspace, acquired by the `downwards-facing' camera. Note that besides correcting for projective distortions, the warp places the axes of the augmentation in accordance with the axes of the `downwards-facing' camera, and that the dimensions of the augmentation are in line with the desired target dimensions (50~cm~$\times $~31.25~cm). To provide context, the corners of the full projected image extent are projected to the floor in light green (emphasized with overlain dashed circles).\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {paragraph}{Plane-induced homography}{17}{section*.10}\protected@file@percent }
\citation{Hartley2004}
\citation{rupprecht2020information,Rupprecht2021}
\newlabel{homgen}{{6}{18}{Plane-induced homography}{equation.2.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Evaluation}{18}{section.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Evaluation scenario. (a) Our hardware setup, comprised of a projector, a steerable mirror system, and a stereo camera, of which we used only the left view. (b) Example augmentation produced by projecting---to one of the 15 target locations across the floorspace considered in our evaluation, to the upper-left corner of our floorspace---an image warped using our approach. The digital angle gauge reads $89.6^\circ {}$ for the top-left corner, and the steel rule 49.9 cm for the bottom edge. Corners of the full projected image extent projected to the floor in light green to provide context. Note that blur has a minimal impact on the quality of the augmentation, and hence on the accuracy of the measurements.\relax }}{19}{figure.caption.11}\protected@file@percent }
\newlabel{fig:eval}{{7}{19}{Evaluation scenario. (a) Our hardware setup, comprised of a projector, a steerable mirror system, and a stereo camera, of which we used only the left view. (b) Example augmentation produced by projecting---to one of the 15 target locations across the floorspace considered in our evaluation, to the upper-left corner of our floorspace---an image warped using our approach. The digital angle gauge reads $89.6^\circ {}$ for the top-left corner, and the steel rule 49.9 cm for the bottom edge. Corners of the full projected image extent projected to the floor in light green to provide context. Note that blur has a minimal impact on the quality of the augmentation, and hence on the accuracy of the measurements.\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {\centering Hardware setup consisting of a Panasonic PT-RZ660BE projector, a steerable mirror system manufactured by Dynamic Projection Institute, and the left view of a Stereolabs Zed 2 stereo camera---placed to face downwards towards the scene plane---to serve as the `downwards-facing' camera.}}}{19}{subfigure.7.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {\centering Measurement for augmentation, using a steel rule and a digital angle gauge (enlargements on the right).}}}{19}{subfigure.7.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Mean absolute error (MAE) and maximum absolute error in units of centimeters, with respect to the four sides (top, bottom, left, right) of the 15\nobreakspace  {}augmentations produced using our approach for 15 target locations spread across the floorspace, respectively. Errors were computed against intended augmentation dimensions of 50\nobreakspace  {}cm\nobreakspace  {}$\times $\nobreakspace  {}31.25\nobreakspace  {}cm (i.e., 50\nobreakspace  {}cm for top and bottom, 31.25\nobreakspace  {}cm---rounded to 31.3\nobreakspace  {}cm for the purposes of the computing the errors---for left and right).\relax }}{20}{table.caption.12}\protected@file@percent }
\newlabel{table:length}{{1}{20}{Mean absolute error (MAE) and maximum absolute error in units of centimeters, with respect to the four sides (top, bottom, left, right) of the 15~augmentations produced using our approach for 15 target locations spread across the floorspace, respectively. Errors were computed against intended augmentation dimensions of 50~cm~$\times $~31.25~cm (i.e., 50~cm for top and bottom, 31.25~cm---rounded to 31.3~cm for the purposes of the computing the errors---for left and right).\relax }{table.caption.12}{}}
\@writefile{toc}{\contentsline {paragraph}{Manual approach}{20}{section*.13}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Mean absolute error (MAE) and maximum absolute error in units of degrees, with respect to the top-left and bottom-right corners of the 15\nobreakspace  {}augmentations produced using our approach for 15 target locations spread across the floorspace, respectively. Errors computed in terms of deviation from $90^\circ {}$.\relax }}{21}{table.caption.14}\protected@file@percent }
\newlabel{table:angle}{{2}{21}{Mean absolute error (MAE) and maximum absolute error in units of degrees, with respect to the top-left and bottom-right corners of the 15~augmentations produced using our approach for 15 target locations spread across the floorspace, respectively. Errors computed in terms of deviation from $90^\circ {}$.\relax }{table.caption.14}{}}
\@writefile{toc}{\contentsline {paragraph}{Our approach}{21}{section*.15}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Conclusion}{22}{section.4}\protected@file@percent }
\bibdata{mybibfile}
\bibcite{van2010survey}{{1}{}{{}}{{}}}
\bibcite{zhou2008trends}{{2}{}{{}}{{}}}
\bibcite{schlund2018moglichkeiten}{{3}{}{{}}{{}}}
\bibcite{uva2018evaluating}{{4}{}{{}}{{}}}
\bibcite{masood2019augmented}{{5}{}{{}}{{}}}
\bibcite{gattullo2019towards}{{6}{}{{}}{{}}}
\bibcite{aschenbrenner2019comparing}{{7}{}{{}}{{}}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Acknowledgments}{23}{section.5}\protected@file@percent }
\bibcite{mayrhofer2019one}{{8}{}{{}}{{}}}
\bibcite{rupprecht2020information}{{9}{}{{}}{{}}}
\bibcite{Rupprecht2021}{{10}{}{{}}{{}}}
\bibcite{hololens}{{11}{}{{}}{{}}}
\bibcite{bimber2019spatial}{{12}{}{{}}{{}}}
\bibcite{pinhanez2001everywhere}{{13}{}{{}}{{}}}
\bibcite{kjeldsen2002interacting}{{14}{}{{}}{{}}}
\bibcite{pinhanez2003applications}{{15}{}{{}}{{}}}
\bibcite{Hartley2004}{{16}{}{{}}{{}}}
\bibcite{sukthankar2001smarter}{{17}{}{{}}{{}}}
\bibcite{raskar2001self}{{18}{}{{}}{{}}}
\bibcite{duane1971close}{{19}{}{{}}{{}}}
\bibcite{weng1992camera}{{20}{}{{}}{{}}}
\bibcite{triggs1999bundle}{{21}{}{{}}{{}}}
\bibcite{zhang2000flexible}{{22}{}{{}}{{}}}
\bibcite{moreno2012simple}{{23}{}{{}}{{}}}
\bibcite{zhang2009projector}{{24}{}{{}}{{}}}
\bibcite{zhang2006novel}{{25}{}{{}}{{}}}
\bibcite{bradski2000opencv}{{26}{}{{}}{{}}}
\bibcite{collins2014infinitesimal}{{27}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
