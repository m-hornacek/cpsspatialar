\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{elsarticle-num}
\emailauthor{michael.hornacek@tuwien.ac.at}{Michael Horn\'{a}\v {c}ek}
\Newlabel{mycorrespondingauthor}{1}
\citation{van2010survey,zhou2008trends}
\citation{schlund2018moglichkeiten,uva2018evaluating,masood2019augmented,gattullo2019towards,aschenbrenner2019comparing,mayrhofer2019one,rupprecht2020information,Rupprecht2021}
\citation{hololens}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}\protected@file@percent }
\newlabel{sec:intro}{{1}{2}{Introduction}{section.1}{}}
\citation{bimber2019spatial}
\citation{aschenbrenner2019comparing}
\citation{mayrhofer2019one}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Na\"ive projection to a given target location in the scene plane (e.g., the floor, a wall, or table). (a) Original image, which we wish to project to the scene plane. (b) Projecting the original image to the scene plane from the viewpoint of the projector directed to the target location (bottom left, black with up vector red) introduces projective distortions if the projector is not fronto-parallel with the scene plane (as is the case here), with orientation and scale varying as a function of target location.\relax }}{3}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:proj}{{1}{3}{Na\"ive projection to a given target location in the scene plane (e.g., the floor, a wall, or table). (a) Original image, which we wish to project to the scene plane. (b) Projecting the original image to the scene plane from the viewpoint of the projector directed to the target location (bottom left, black with up vector red) introduces projective distortions if the projector is not fronto-parallel with the scene plane (as is the case here), with orientation and scale varying as a function of target location.\relax }{figure.caption.1}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {\centering Original image.}}}{3}{subfigure.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {\centering Projection to target location in scene plane (view downwards to scene plane).}}}{3}{subfigure.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Projection to a given target location in the scene plane, correcting for projective distortions using our approach. (a) Original image (cf.\ Figure\nobreakspace  {}\ref  {fig:proj}(a)) warped using our approach with respect to the given target location. (b) Projecting the warped image to the scene plane from the viewpoint of the projector directed to the target location (bottom left, black with up vector red; same as in Figure\nobreakspace  {}\ref  {fig:proj}(b)) has the effect of projecting the \textit  {original} image from the viewpoint of the \textit  {virtual} projector (center, gray with up vector red). This renders the projection free of projective distortions, aligned with the axes of the virtual camera, and at the desired metric scale. Note that black pixels will in effect be ignored by the projector.\relax }}{5}{figure.caption.2}\protected@file@percent }
\newlabel{fig:warp}{{2}{5}{Projection to a given target location in the scene plane, correcting for projective distortions using our approach. (a) Original image (cf.\ Figure~\ref {fig:proj}(a)) warped using our approach with respect to the given target location. (b) Projecting the warped image to the scene plane from the viewpoint of the projector directed to the target location (bottom left, black with up vector red; same as in Figure~\ref {fig:proj}(b)) has the effect of projecting the \textit {original} image from the viewpoint of the \textit {virtual} projector (center, gray with up vector red). This renders the projection free of projective distortions, aligned with the axes of the virtual camera, and at the desired metric scale. Note that black pixels will in effect be ignored by the projector.\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {\centering Our warped image.}}}{5}{subfigure.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {\centering Projection to target location in scene plane (view downwards to scene plane).}}}{5}{subfigure.2.2}\protected@file@percent }
\citation{pinhanez2001everywhere}
\citation{kjeldsen2002interacting,pinhanez2003applications}
\citation{Hartley2004}
\citation{Hartley2004}
\citation{sukthankar2001smarter}
\citation{raskar2001self}
\citation{Hartley2004}
\citation{bimber2019spatial}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Related Work}{6}{subsection.1.1}\protected@file@percent }
\citation{Hartley2004}
\@writefile{toc}{\contentsline {section}{\numberline {2}Approach}{7}{section.2}\protected@file@percent }
\citation{Hartley2004}
\citation{duane1971close,weng1992camera}
\citation{Hartley2004}
\citation{triggs1999bundle}
\citation{Hartley2004,zhang2000flexible}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Recovering Geometry}{8}{subsection.2.1}\protected@file@percent }
\newlabel{sec:approach:geometry}{{2.1}{8}{Recovering Geometry}{subsection.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Obtaining the 3D positions of the 2D-3D correspondences for use in projector calibration. (a) For each target location, a projector calibration image is acquired from the viewpoint of the `downwards-facing' camera, containing a projected asymmetric circle pattern at the target location and a chessboard pattern placed on the floor nearby. Circle pattern center points and chessboard corners detected automatically (overlain for illustration). (b) Given a projector calibration image, the scene plane is recovered in the coordinate frame of the camera (black with up vector red) via spatial resection with respect to 2D-3D correspondences obtained using the chessboard pattern (blue); the 3D positions of the 2D-3D correspondences to be used in calibrating the projector (red, in scene plane) are obtained by intersection with the scene plane of the back-projections (rays, likewise gray) of the 2D center points of the circle pattern detected in the image plane of the camera.\relax }}{9}{figure.caption.3}\protected@file@percent }
\newlabel{fig:2d}{{3}{9}{Obtaining the 3D positions of the 2D-3D correspondences for use in projector calibration. (a) For each target location, a projector calibration image is acquired from the viewpoint of the `downwards-facing' camera, containing a projected asymmetric circle pattern at the target location and a chessboard pattern placed on the floor nearby. Circle pattern center points and chessboard corners detected automatically (overlain for illustration). (b) Given a projector calibration image, the scene plane is recovered in the coordinate frame of the camera (black with up vector red) via spatial resection with respect to 2D-3D correspondences obtained using the chessboard pattern (blue); the 3D positions of the 2D-3D correspondences to be used in calibrating the projector (red, in scene plane) are obtained by intersection with the scene plane of the back-projections (rays, likewise gray) of the 2D center points of the circle pattern detected in the image plane of the camera.\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {\centering Projector calibration image (2D pattern position detections overlain).}}}{9}{subfigure.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {\centering Corresponding 3D positions for use in projector calibration (red, in scene plane).}}}{9}{subfigure.3.2}\protected@file@percent }
\citation{duane1971close,weng1992camera}
\citation{moreno2012simple,zhang2009projector,zhang2006novel}
\citation{bradski2000opencv}
\newlabel{re}{{2}{10}{Recovering Geometry}{equation.2.2}{}}
\citation{Hartley2004}
\citation{collins2014infinitesimal}
\citation{bradski2000opencv}
\@writefile{toc}{\contentsline {paragraph}{2D-3D correspondences for camera calibration}{11}{section*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{2D-3D correspondences for projector calibration}{11}{section*.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Obtaining the virtual camera. Our physical `downwards-facing' camera---in terms of whose rotation relative to the scene plane we wish to orient our augmentations---is almost certain to not face downwards precisely. Accordingly, we rotate the recovered `downwards-facing' camera (black) about its center of projection such that its optical axis be made parallel with the scene plane's normal, with respect to the minimum arc-length rotation. It is then, for each respective target position, the $X$- and $Y$-axes of the resulting \textit  {virtual} camera (gray) that we subsequently use to orient our virtual projector.\relax }}{13}{figure.caption.6}\protected@file@percent }
\newlabel{fig:virtualcam}{{4}{13}{Obtaining the virtual camera. Our physical `downwards-facing' camera---in terms of whose rotation relative to the scene plane we wish to orient our augmentations---is almost certain to not face downwards precisely. Accordingly, we rotate the recovered `downwards-facing' camera (black) about its center of projection such that its optical axis be made parallel with the scene plane's normal, with respect to the minimum arc-length rotation. It is then, for each respective target position, the $X$- and $Y$-axes of the resulting \textit {virtual} camera (gray) that we subsequently use to orient our virtual projector.\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {\centering Oblique view (annotated).}}}{13}{subfigure.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {\centering View downwards to scene plane.}}}{13}{subfigure.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Correcting for Projective Distortion}{13}{subsection.2.2}\protected@file@percent }
\newlabel{sec:approach:homography}{{2.2}{13}{Correcting for Projective Distortion}{subsection.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Obtaining the virtual projector. For a given target location, the virtual projector is obtained by (i) rotating the recovered projector (bottom left, black) about the point of intersection of its optical axis with the scene plane such that the optical axis be made parallel with the scene plane's normal vector, (ii) rotating the $X$- and $Y$-axes to align them with those of the virtual camera guaranteed---in contrast to the `downwards-facing' camera---to face \textit  {directly} downwards to the scene plane (cf.\ Figure \ref  {fig:virtualcam}), and (iii) translating along the normal direction to achieve the desired metric projected image dimensions.\relax }}{14}{figure.caption.7}\protected@file@percent }
\newlabel{fig:virtualproj}{{5}{14}{Obtaining the virtual projector. For a given target location, the virtual projector is obtained by (i) rotating the recovered projector (bottom left, black) about the point of intersection of its optical axis with the scene plane such that the optical axis be made parallel with the scene plane's normal vector, (ii) rotating the $X$- and $Y$-axes to align them with those of the virtual camera guaranteed---in contrast to the `downwards-facing' camera---to face \textit {directly} downwards to the scene plane (cf.\ Figure \ref {fig:virtualcam}), and (iii) translating along the normal direction to achieve the desired metric projected image dimensions.\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {\centering Oblique view (annotated).}}}{14}{subfigure.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {\centering View downwards to scene plane.}}}{14}{subfigure.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Virtual projector}{14}{section*.8}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Plane-induced homography}{15}{section*.9}\protected@file@percent }
\citation{Hartley2004}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Evaluation scenario. (a) Our hardware setup, comprised of a projector, a steerable mirror system, and a stereo camera, of which we used only the left view. (b) Example augmentation produced by projecting---to one of the 15 target locations across the floorspace considered in our evaluation---an image warped using our approach, as seen from the `downwards-facing' camera. Note that the warp places the axes of the augmentation in accordance with the axes of the camera, and that the dimensions of the augmentation are in line with the desired target dimensions (50\nobreakspace  {}cm\nobreakspace  {}$\times $\nobreakspace  {}31.25\nobreakspace  {}cm). Corners of the full projected image extent projected to the floor in light green (emphasized with overlain dashed circles).\relax }}{16}{figure.caption.10}\protected@file@percent }
\newlabel{fig:eval}{{6}{16}{Evaluation scenario. (a) Our hardware setup, comprised of a projector, a steerable mirror system, and a stereo camera, of which we used only the left view. (b) Example augmentation produced by projecting---to one of the 15 target locations across the floorspace considered in our evaluation---an image warped using our approach, as seen from the `downwards-facing' camera. Note that the warp places the axes of the augmentation in accordance with the axes of the camera, and that the dimensions of the augmentation are in line with the desired target dimensions (50~cm~$\times $~31.25~cm). Corners of the full projected image extent projected to the floor in light green (emphasized with overlain dashed circles).\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {\centering Hardware setup (projector, steerable mirror system, camera).}}}{16}{subfigure.6.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {\centering Projection of warped image from Figure\nobreakspace {}\ref {fig:warp}(a) to corresponding target location.}}}{16}{subfigure.6.2}\protected@file@percent }
\newlabel{homgen}{{6}{16}{Plane-induced homography}{equation.2.6}{}}
\citation{rupprecht2020information,Rupprecht2021}
\@writefile{toc}{\contentsline {section}{\numberline {3}Evaluation}{17}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Manual approach}{18}{section*.11}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Means and standard deviations (in units of centimeters and pixels, respectively) of deviations in measured lengths from 50 cm for top and bottom and from 21.25 cm for left and right, with respect to the 15 augmentations produced using our approach for 15 respective target locations (intended augmentation dimensions 50\nobreakspace  {}cm\nobreakspace  {}$\times $\nobreakspace  {}31.25\nobreakspace  {}cm). Pixel size given the downward-facing camera's height above the ground plane was 3.5 mm; note that in no instance did mean and standard deviation exceed 1 pixel from the viewpoint of the camera.\relax }}{18}{table.caption.12}\protected@file@percent }
\newlabel{table:length}{{1}{18}{Means and standard deviations (in units of centimeters and pixels, respectively) of deviations in measured lengths from 50 cm for top and bottom and from 21.25 cm for left and right, with respect to the 15 augmentations produced using our approach for 15 respective target locations (intended augmentation dimensions 50~cm~$\times $~31.25~cm). Pixel size given the downward-facing camera's height above the ground plane was 3.5 mm; note that in no instance did mean and standard deviation exceed 1 pixel from the viewpoint of the camera.\relax }{table.caption.12}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Means and standard deviations of deviations in measured angles from $90^\circ {}$ with respect to the 15 augmentations produced using our approach for 15 respective target locations.\relax }}{18}{table.caption.13}\protected@file@percent }
\newlabel{table:angle}{{2}{18}{Means and standard deviations of deviations in measured angles from $90^\circ {}$ with respect to the 15 augmentations produced using our approach for 15 respective target locations.\relax }{table.caption.13}{}}
\@writefile{toc}{\contentsline {paragraph}{Our approach}{19}{section*.14}\protected@file@percent }
\bibdata{mybibfile}
\bibcite{van2010survey}{{1}{}{{}}{{}}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Conclusion}{20}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Acknowledgments}{20}{section.5}\protected@file@percent }
\bibcite{zhou2008trends}{{2}{}{{}}{{}}}
\bibcite{schlund2018moglichkeiten}{{3}{}{{}}{{}}}
\bibcite{uva2018evaluating}{{4}{}{{}}{{}}}
\bibcite{masood2019augmented}{{5}{}{{}}{{}}}
\bibcite{gattullo2019towards}{{6}{}{{}}{{}}}
\bibcite{aschenbrenner2019comparing}{{7}{}{{}}{{}}}
\bibcite{mayrhofer2019one}{{8}{}{{}}{{}}}
\bibcite{rupprecht2020information}{{9}{}{{}}{{}}}
\bibcite{Rupprecht2021}{{10}{}{{}}{{}}}
\bibcite{hololens}{{11}{}{{}}{{}}}
\bibcite{bimber2019spatial}{{12}{}{{}}{{}}}
\bibcite{pinhanez2001everywhere}{{13}{}{{}}{{}}}
\bibcite{kjeldsen2002interacting}{{14}{}{{}}{{}}}
\bibcite{pinhanez2003applications}{{15}{}{{}}{{}}}
\bibcite{Hartley2004}{{16}{}{{}}{{}}}
\bibcite{sukthankar2001smarter}{{17}{}{{}}{{}}}
\bibcite{raskar2001self}{{18}{}{{}}{{}}}
\bibcite{duane1971close}{{19}{}{{}}{{}}}
\bibcite{weng1992camera}{{20}{}{{}}{{}}}
\bibcite{triggs1999bundle}{{21}{}{{}}{{}}}
\bibcite{zhang2000flexible}{{22}{}{{}}{{}}}
\bibcite{moreno2012simple}{{23}{}{{}}{{}}}
\bibcite{zhang2009projector}{{24}{}{{}}{{}}}
\bibcite{zhang2006novel}{{25}{}{{}}{{}}}
\bibcite{bradski2000opencv}{{26}{}{{}}{{}}}
\bibcite{collins2014infinitesimal}{{27}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
