\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{elsarticle-num}
\emailauthor{michael.hornacek@tuwien.ac.at}{Michael Horn\'{a}\v {c}ek}
\Newlabel{mycorrespondingauthor}{1}
\citation{van2010survey,zhou2008trends}
\citation{schlund2018moglichkeiten,uva2018evaluating,masood2019augmented,gattullo2019towards,aschenbrenner2019comparing,mayrhofer2019one,rupprecht2020information,Rupprecht2021}
\citation{hololens}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}\protected@file@percent }
\newlabel{sec:intro}{{1}{2}{Introduction}{section.1}{}}
\citation{bimber2019spatial}
\citation{aschenbrenner2019comparing}
\citation{mayrhofer2019one}
\citation{pinhanez2001everywhere}
\citation{kjeldsen2002interacting,pinhanez2003applications}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Related Work}{4}{subsection.1.1}\protected@file@percent }
\citation{Hartley2004}
\citation{Hartley2004}
\citation{sukthankar2001smarter}
\citation{raskar2001self}
\citation{Hartley2004}
\citation{bimber2019spatial}
\@writefile{toc}{\contentsline {section}{\numberline {2}Approach}{6}{section.2}\protected@file@percent }
\citation{Hartley2004}
\citation{duane1971close,weng1992camera}
\citation{triggs1999bundle}
\citation{Hartley2004,zhang2000flexible}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Recovering Geometry}{7}{subsection.2.1}\protected@file@percent }
\newlabel{sec:approach:geometry}{{2.1}{7}{Recovering Geometry}{subsection.2.1}{}}
\citation{duane1971close,weng1992camera}
\citation{moreno2012simple,zhang2009projector,zhang2006novel}
\newlabel{re}{{2}{8}{Recovering Geometry}{equation.2.2}{}}
\citation{bradski2000opencv}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Recovering 2D positions in support of projector calibration. (a) The asymmetrical circle pattern that we project to each of the target locations in the scene plane. 2D positions of the 2D-3D correspondences to be used for calibrating the projector are detected automatically, as the respective circle centers in the asymmetrical circle pattern image and given in a fixed ordering. (b) For each such target location, a projector calibration image is acquired from the viewpoint of the camera and the circle centers of the projected asymmetrical circle pattern are detected using the same algorithm as in (a). A chessboard pattern to be used for recovering the local scene plane is placed near the projected pattern, whose corners are likewise detected. Detected 2D projected asymmetrical circle pattern circle center points and chessboard corners overlain for illustration.\relax }}{9}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:2d}{{1}{9}{Recovering 2D positions in support of projector calibration. (a) The asymmetrical circle pattern that we project to each of the target locations in the scene plane. 2D positions of the 2D-3D correspondences to be used for calibrating the projector are detected automatically, as the respective circle centers in the asymmetrical circle pattern image and given in a fixed ordering. (b) For each such target location, a projector calibration image is acquired from the viewpoint of the camera and the circle centers of the projected asymmetrical circle pattern are detected using the same algorithm as in (a). A chessboard pattern to be used for recovering the local scene plane is placed near the projected pattern, whose corners are likewise detected. Detected 2D projected asymmetrical circle pattern circle center points and chessboard corners overlain for illustration.\relax }{figure.caption.1}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {\centering Asymmetrical circle pattern image, in image plane of projector (detections overlaid).}}}{9}{subfigure.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {\centering Projector calibration image (one for each target location), in image plane of camera (detections overlaid).}}}{9}{subfigure.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{2D-3D correspondences for camera calibration}{9}{section*.2}\protected@file@percent }
\citation{bradski2000opencv}
\@writefile{toc}{\contentsline {paragraph}{2D-3D correspondences for projector calibration}{10}{section*.3}\protected@file@percent }
\citation{collins2014infinitesimal}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Obtaining 2D-3D correspondences for projector calibration, using a projector calibration image (cf.\ Figure\nobreakspace  {}\ref  {fig:2d}(b)). First, the scene plane (gray) is recovered via spatial resection with respect to 2D-3D correspondences obtained using a chessboard pattern (blue); 3D circle center points of the asymmetrical circle pattern---i.e., the 3D positions of the 2D-3D correspondences to be used for calibrating the projector (red)---obtained by intersection with the scene plane of back-projections (likewise gray) of the 2D circle center points of the asymmetrical circle pattern detected in the image plane. The downwards-facing camera is shown in terms of its camera frustum (black, with up vector in red).\relax }}{11}{figure.caption.4}\protected@file@percent }
\newlabel{fig:3d}{{2}{11}{Obtaining 2D-3D correspondences for projector calibration, using a projector calibration image (cf.\ Figure~\ref {fig:2d}(b)). First, the scene plane (gray) is recovered via spatial resection with respect to 2D-3D correspondences obtained using a chessboard pattern (blue); 3D circle center points of the asymmetrical circle pattern---i.e., the 3D positions of the 2D-3D correspondences to be used for calibrating the projector (red)---obtained by intersection with the scene plane of back-projections (likewise gray) of the 2D circle center points of the asymmetrical circle pattern detected in the image plane. The downwards-facing camera is shown in terms of its camera frustum (black, with up vector in red).\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Obtaining the virtual camera. A physical camera placed to face downwards is almost certain to not face downwards precisely. We correct for this possibility by rotating the recovered downwards-facing camera (black) about its center of projection such that its optical axis be made parallel with the plane's normal. Since it is in accordance with our downwards-facing camera the we wish to orient our virtual projector and since our virtual projector is required to face directly downwards to the scene plane to compute our corrective image warp, it is the orientiation of the virtual camera that we use to subsequently orient our virtual projector.\relax }}{12}{figure.caption.5}\protected@file@percent }
\newlabel{fig:virtualcam}{{3}{12}{Obtaining the virtual camera. A physical camera placed to face downwards is almost certain to not face downwards precisely. We correct for this possibility by rotating the recovered downwards-facing camera (black) about its center of projection such that its optical axis be made parallel with the plane's normal. Since it is in accordance with our downwards-facing camera the we wish to orient our virtual projector and since our virtual projector is required to face directly downwards to the scene plane to compute our corrective image warp, it is the orientiation of the virtual camera that we use to subsequently orient our virtual projector.\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {\centering Oblique view (annotated).}}}{12}{subfigure.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {\centering Downwards view.}}}{12}{subfigure.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Obtaining the virtual projector. The virtual projector is then obtained by (i) rotating the recovered projector (black) about the point of intersection of its optical axis with the scene plane such that the optical axis be made parallel with the scene plane's normal vector, (ii) rotating the $X$- and $Y$-axes to align them with those of the virtual camera, and (iii) translating along the normal direction to achieve the desired metric projected image dimensions.\relax }}{13}{figure.caption.6}\protected@file@percent }
\newlabel{fig:virtualproj}{{4}{13}{Obtaining the virtual projector. The virtual projector is then obtained by (i) rotating the recovered projector (black) about the point of intersection of its optical axis with the scene plane such that the optical axis be made parallel with the scene plane's normal vector, (ii) rotating the $X$- and $Y$-axes to align them with those of the virtual camera, and (iii) translating along the normal direction to achieve the desired metric projected image dimensions.\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {\centering Oblique view (annotated).}}}{13}{subfigure.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {\centering Downwards view.}}}{13}{subfigure.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Correcting for Projective Distortion}{13}{subsection.2.2}\protected@file@percent }
\newlabel{sec:approach:homography}{{2.2}{13}{Correcting for Projective Distortion}{subsection.2.2}{}}
\citation{Hartley2004}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Projection to the scene plane from the recovered projector viewpoint (bottom left, black; virtual projector in center, gray) of the original image and of the warped image. (a) Projecting the original image to the scene plane. (b) After warping the original image according to our plane-induced homography for the given target location, the image is projected in a manner that appears free of projective distortions, aligned with the axes of the virtual camera (via the virtual projector), and to have the desired dimensions in the scene plane, expressed in metric units. Note that unprojected background is shown set to black.\relax }}{14}{figure.caption.7}\protected@file@percent }
\newlabel{fig:warp}{{5}{14}{Projection to the scene plane from the recovered projector viewpoint (bottom left, black; virtual projector in center, gray) of the original image and of the warped image. (a) Projecting the original image to the scene plane. (b) After warping the original image according to our plane-induced homography for the given target location, the image is projected in a manner that appears free of projective distortions, aligned with the axes of the virtual camera (via the virtual projector), and to have the desired dimensions in the scene plane, expressed in metric units. Note that unprojected background is shown set to black.\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {\centering Projecting original image.}}}{14}{subfigure.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {\centering Projecting our warped image.}}}{14}{subfigure.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Plane-induced homography}{14}{section*.8}\protected@file@percent }
\newlabel{homgen}{{3}{14}{Plane-induced homography}{equation.2.3}{}}
\@writefile{toc}{\contentsline {paragraph}{Virtual projector}{15}{section*.9}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Evaluation scenario. (a) Our hardware setup, comprised of a Panasonic PT-RZ660BE projector, a steerable mirror system manufactured by Dynamic Projection Institute, and a Stereolabs Zed 2 stereo camera, of which we used only the left view. (b) Example augmentation produced by projecting---to one of our 15 target locations---an image warped using our approach, as seen from the downwards-facing camera. Note that the warp places the axes of the augmentation in accordance with the axes of the camera, and that the dimensions of the augmentation are in line with the desired target dimensions (50\nobreakspace  {}cm\nobreakspace  {}$\times $\nobreakspace  {}31.25\nobreakspace  {}cm). Corners of the full projected image extent projected to the floor in light green.\relax }}{16}{figure.caption.10}\protected@file@percent }
\newlabel{fig:eval}{{6}{16}{Evaluation scenario. (a) Our hardware setup, comprised of a Panasonic PT-RZ660BE projector, a steerable mirror system manufactured by Dynamic Projection Institute, and a Stereolabs Zed 2 stereo camera, of which we used only the left view. (b) Example augmentation produced by projecting---to one of our 15 target locations---an image warped using our approach, as seen from the downwards-facing camera. Note that the warp places the axes of the augmentation in accordance with the axes of the camera, and that the dimensions of the augmentation are in line with the desired target dimensions (50~cm~$\times $~31.25~cm). Corners of the full projected image extent projected to the floor in light green.\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {\centering Hardware setup (projector, steerable mirror system, camera).}}}{16}{subfigure.6.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {\centering Example projection of image warped for target location using our approach.}}}{16}{subfigure.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Evaluation}{16}{section.3}\protected@file@percent }
\citation{rupprecht2020information,Rupprecht2021}
\@writefile{toc}{\contentsline {paragraph}{Manual approach}{17}{section*.11}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Deviations in measured lengths from 50\nobreakspace  {}cm\nobreakspace  {}$\times $\nobreakspace  {}31.25\nobreakspace  {}cm across the 15 augmentations produced using our approach, provided in cm and in pixel units of the downwards-facing camera (pixel size 3.5 mm). Note that in no instance do mean and standard deviation exceed 1 pixel from the viewpoint of the camera.\relax }}{18}{table.caption.12}\protected@file@percent }
\newlabel{table:length}{{1}{18}{Deviations in measured lengths from 50~cm~$\times $~31.25~cm across the 15 augmentations produced using our approach, provided in cm and in pixel units of the downwards-facing camera (pixel size 3.5 mm). Note that in no instance do mean and standard deviation exceed 1 pixel from the viewpoint of the camera.\relax }{table.caption.12}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Deviations in measured angles from $90^\circ {}$ across the 15 augmentations produced using our approach.\relax }}{18}{table.caption.13}\protected@file@percent }
\newlabel{table:angle}{{2}{18}{Deviations in measured angles from $90^\circ {}$ across the 15 augmentations produced using our approach.\relax }{table.caption.13}{}}
\@writefile{toc}{\contentsline {paragraph}{Our approach}{18}{section*.14}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Conclusion}{19}{section.4}\protected@file@percent }
\bibdata{mybibfile}
\bibcite{van2010survey}{{1}{}{{}}{{}}}
\bibcite{zhou2008trends}{{2}{}{{}}{{}}}
\bibcite{schlund2018moglichkeiten}{{3}{}{{}}{{}}}
\bibcite{uva2018evaluating}{{4}{}{{}}{{}}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Acknowledgments}{20}{section.5}\protected@file@percent }
\bibcite{masood2019augmented}{{5}{}{{}}{{}}}
\bibcite{gattullo2019towards}{{6}{}{{}}{{}}}
\bibcite{aschenbrenner2019comparing}{{7}{}{{}}{{}}}
\bibcite{mayrhofer2019one}{{8}{}{{}}{{}}}
\bibcite{rupprecht2020information}{{9}{}{{}}{{}}}
\bibcite{Rupprecht2021}{{10}{}{{}}{{}}}
\bibcite{hololens}{{11}{}{{}}{{}}}
\bibcite{bimber2019spatial}{{12}{}{{}}{{}}}
\bibcite{pinhanez2001everywhere}{{13}{}{{}}{{}}}
\bibcite{kjeldsen2002interacting}{{14}{}{{}}{{}}}
\bibcite{pinhanez2003applications}{{15}{}{{}}{{}}}
\bibcite{Hartley2004}{{16}{}{{}}{{}}}
\bibcite{sukthankar2001smarter}{{17}{}{{}}{{}}}
\bibcite{raskar2001self}{{18}{}{{}}{{}}}
\bibcite{duane1971close}{{19}{}{{}}{{}}}
\bibcite{weng1992camera}{{20}{}{{}}{{}}}
\bibcite{triggs1999bundle}{{21}{}{{}}{{}}}
\bibcite{zhang2000flexible}{{22}{}{{}}{{}}}
\bibcite{moreno2012simple}{{23}{}{{}}{{}}}
\bibcite{zhang2009projector}{{24}{}{{}}{{}}}
\bibcite{zhang2006novel}{{25}{}{{}}{{}}}
\bibcite{bradski2000opencv}{{26}{}{{}}{{}}}
\bibcite{collins2014infinitesimal}{{27}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
